# -*- coding: utf-8 -*-
"""2A-IR-DL-regression-linear.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cnSTr3a4Lzz-kukdoXHav19Pk680iXyG

authors: [Ali Ismail-Fawaz](https://hadifawaz1999.github.io/) and [Germain Forestier](https://germain-forestier.info/)

# **Gradient Descent**

Import packages used
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

import tensorflow as tf

"""## Downloading the dataset"""

#!wget https://hadifawaz1999.github.io/teaching/Ensisa/2A-Info/DeepLearning/datasets/pokemon-stats-data.csv

"""## Reading the data"""

df = pd.read_csv(os.path.join(os.path.dirname(__file__), "pokemon-stats-data.csv"))

df = df.dropna()
df.head()

"""## Extract the features to be used"""

X = np.asarray(df[["weight_kg","sp_attack"]], dtype=np.float32)
Y = np.asarray(df["sp_defense"], dtype=np.float32)

print("Number of samples in the dataset is "+str(len(X)))

"""## Split the dataset into train and test sets"""

xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=33/100, random_state=42)

print("Number of training examples is "+str(len(xtrain)))
print("Number of testing examples is "+str(len(xtest)))

"""## Normalize the dataset"""

xtrain = MinMaxScaler().fit_transform(xtrain)
xtest = MinMaxScaler().fit_transform(xtest)

"""## Create using Tensorflow-Keras a linear model

### Create an input layer with the same shape as one example in xtrain
"""

input_shape = xtrain.shape[1:]

input_layer = tf.keras.layers.Input(input_shape)

"""### Create an output layer containing one unit (neuron) with linear activation that takes as input the `input_layer` just created"""

output_layer = tf.keras.layers.Dense(units=1, activation="linear")(input_layer)

"""### Create the model (a perceptron)"""

model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)

model.summary()

"""### Choose the optimiazation algorithm and set the learning rate to $0.1$"""

learning_rate = 0.1
optimizer_algo = tf.keras.optimizers.SGD(learning_rate=learning_rate)

"""### Choose the cost function to optimize: `Mean Squared Error`"""

cost_function = tf.keras.losses.mse

"""### Compile the model"""

model.compile(loss=cost_function, optimizer=optimizer_algo)

"""### Train the model with a `batch size` of $32$ for $100$ epochs"""

mini_batch_size = 64
nb_epochs = 500

tf.random.set_seed(42)

history = model.fit(xtrain,
                    ytrain,
                    batch_size=mini_batch_size,
                    epochs=nb_epochs,
                    verbose=0,)

"""### Plot the error changing with each epoch on the training set"""

history_dict = history.history
loss_epochs = history_dict["loss"]

plt.figure()
plt.plot(loss_epochs)
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.show()
plt.close()

"""### Evaluate the model on the train set"""

loss_train = model.evaluate(xtrain, ytrain, verbose=False)
print("The error on the train set is = "+str(loss_train))

"""## Plot the predictions in the case of a plane

### Plot the training data without the predictions
"""

fig = plt.figure()

plot3d = fig.add_subplot(111, projection="3d")

ax = plt.gca()

ax.view_init(elev=10, azim=20)

plot3d.scatter(xtrain[:,0], xtrain[:,1], ytrain)

ax.set_xlabel("Weight (x1)")
ax.set_ylabel("Attack (x2)")
ax.set_zlabel("Defense (y)")

plt.show()
plt.close()

"""### Recover the learned parameters"""

learned_parameters = model.layers[-1].get_weights()

w = learned_parameters[0]
b = learned_parameters[1]

print("w = "+str(w))
print("b = "+str(b))

"""### Plot the decision plane"""

x1_min = xtrain[:,0].min()
x1_max = xtrain[:,0].max()
x2_min = xtrain[:,1].min()
x2_max = xtrain[:,1].max()

nb_points_plane = 100

x1 = np.linspace(start=x1_min, stop=x1_max, num=nb_points_plane)
x1 = x1.reshape(-1,1)
x2 = np.linspace(start=x2_min, stop=x2_max, num=nb_points_plane)
x2 = x2.reshape(-1,1)

X = np.concatenate((x1,x2), axis=1)
ypred = model.predict(X)

Xmesh1, Xmesh2 = np.meshgrid(x1, x2)

for angle in range(59, 180, 30):
  fig = plt.figure()
  plot3d = fig.add_subplot(111, projection="3d")
  ax = plt.gca()

  ax.set_xlabel("Weight (x1)")
  ax.set_ylabel("Attack (x2)")
  ax.set_zlabel("Defense (y)")

  ax.view_init(elev=10, azim=angle)

  plot3d.scatter(xtrain[:,0], xtrain[:,1], ytrain)
  plot3d.plot_surface(Xmesh1, Xmesh2, ypred, color="green", rstride=100, cstride=100, alpha=0.5, edgecolor='black')

"""# **Exercise**

## Evaluate on the test set
"""
loss_test = model.evaluate(xtest, ytest, verbose=False)
print("The error on the test set is = "+str(loss_test))


"""## Plot the predicted defense values with respect to the true values of the test set"""
ypred_test = model.predict(xtest)
min_ypred, min_ytest = np.min(ypred_test), np.min(ytest)
max_ypred, max_ytest = np.max(ypred_test), np.max(ytest)
plt.figure()
plt.scatter(ytest, ypred_test, alpha=0.7)
plt.plot([min_ytest, max_ytest], [min_ytest, max_ytest], color='red', linestyle='--', lw=2)
plt.xlim(min(min_ypred, min_ytest), max(max_ypred, max_ytest))
plt.ylim(min(min_ypred, min_ytest), max(max_ypred, max_ytest))
plt.xlabel("Ground truth ytest")
plt.ylabel("Predictions ypred")
plt.show()
plt.close()


"""## Train a model while taking 2 attributes (weight and speed) and a non-linear relationship between these 2 attributes"""
X_nonlinear = np.asarray(df[["weight_kg","speed"]], dtype=np.float32)
Y_nonlinear = np.asarray(df["sp_defense"], dtype=np.float32)

xtrain_nonlinear, xtest_nonlinear, ytrain_nonlinear, ytest_nonlinear = train_test_split(X_nonlinear, Y_nonlinear, test_size=33/100, random_state=42)

xtrain_nonlinear = MinMaxScaler().fit_transform(xtrain_nonlinear)
xtest_nonlinear = MinMaxScaler().fit_transform(xtest_nonlinear)

input_shape_nonlinear = xtrain_nonlinear.shape[1:]

input_layer_nonlinear = tf.keras.layers.Input(input_shape_nonlinear)
hidden_layer_nonlinear = tf.keras.layers.Dense(units=10, activation="relu")(input_layer_nonlinear) # Non-linear hidden layer
output_layer_nonlinear = tf.keras.layers.Dense(units=1, activation="linear")(hidden_layer_nonlinear)

model_nonlinear = tf.keras.models.Model(inputs=input_layer_nonlinear, outputs=output_layer_nonlinear)

model_nonlinear.summary()

learning_rate_nonlinear = 0.1
optimizer_algo_nonlinear = tf.keras.optimizers.SGD(learning_rate=learning_rate_nonlinear)
cost_function_nonlinear = tf.keras.losses.mse

model_nonlinear.compile(loss=cost_function_nonlinear, optimizer=optimizer_algo_nonlinear)

mini_batch_size_nonlinear = 64
nb_epochs_nonlinear = 500

tf.random.set_seed(42)

history_nonlinear = model_nonlinear.fit(xtrain_nonlinear,
                                        ytrain_nonlinear,
                                        batch_size=mini_batch_size_nonlinear,
                                        epochs=nb_epochs_nonlinear,
                                        verbose=0,)
"""## Plot the predicted values with respect to the real values of the test set"""
ypred_test_nonlinear = model_nonlinear.predict(xtest_nonlinear)
min_ypred_nonlinear, min_ytest_nonlinear = np.min(ypred_test_nonlinear), np.min(ytest_nonlinear)
max_ypred_nonlinear, max_ytest_nonlinear = np.max(ypred_test_nonlinear), np.max(ytest_nonlinear)
plt.figure()
plt.scatter(ytest_nonlinear, ypred_test_nonlinear, alpha=0.7)
plt.plot([min_ytest_nonlinear, max_ytest_nonlinear], [min_ytest_nonlinear, max_ytest_nonlinear], color='red', linestyle='--', lw=2)
plt.xlim(min(min_ypred_nonlinear, min_ytest_nonlinear), max(max_ypred_nonlinear, max_ytest_nonlinear))
plt.ylim(min(min_ypred_nonlinear, min_ytest_nonlinear), max(max_ypred_nonlinear, max_ytest_nonlinear))
plt.xlabel("Ground truth ytest")
plt.ylabel("Predictions ypred")
plt.show()
plt.close()