# -*- coding: utf-8 -*-
"""2A-IR-DL-Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JDPSKpjH5TPA_XGr_WUdNE9M_mmzc-Wn

authors: [Ali Ismail-Fawaz](https://hadifawaz1999.github.io/) and [Germain Forestier](https://germain-forestier.info/)

# **Classification**

Import packages used
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

import tensorflow as tf

"""## Downloading the dataset"""

#!wget https://hadifawaz1999.github.io/teaching/Ensisa/2A-Info/DeepLearning/datasets/pokemon-stats-data.csv

"""## Reading the data"""

df = pd.read_csv(os.path.join(os.path.dirname(__file__), "pokemon-stats-data.csv"))
df = df.dropna()

df = df[(df["type"] == "fairy") | (df["type"] == "ghost") | (df["type"] == "poison")]

df.head()

"""## Extract the features to be used"""

X = np.asarray(df[["weight_kg","speed","sp_attack","sp_defense"]], dtype=np.float32)
Y_text = np.asarray(df["type"], dtype=str)
Y = LabelEncoder().fit_transform(Y_text)

print("Number of samples in the dataset is "+str(len(X)))
print(np.unique(Y, return_counts=True))

"""## Split the dataset into train and test sets"""

xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=33/100, random_state=42, stratify=Y)

print("Number of training examples is "+str(len(xtrain)))
print("Number of testing examples is "+str(len(xtest)))

"""## Normalize the dataset"""

min_max_scaler = MinMaxScaler().fit(xtrain)
xtrain = min_max_scaler.transform(xtrain)
xtest = min_max_scaler.transform(xtest)

"""## Transforming labels to Binary Classification

class 0: poison
class 1: not-poison
"""

ytrain_binary = np.zeros(shape=ytrain.shape)
ytest_binary = np.zeros(shape=ytest.shape)

ytrain_binary[ytrain == 0] = 0
ytrain_binary[ytrain != 0] = 1

ytest_binary[ytest == 0] = 0
ytest_binary[ytest != 0] = 1

"""## Create using Tensorflow-Keras a linear model"""

input_shape = xtrain.shape[1:]
input_layer = tf.keras.layers.Input(input_shape)

output_layer = tf.keras.layers.Dense(units=1, activation="sigmoid")(input_layer)

model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)
model.compile(loss="binary_crossentropy",
              optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),
              metrics=["accuracy"])

model.summary()

"""## Train the model on the Binary Classification task"""

tf.random.set_seed(42)

history = model.fit(xtrain, ytrain_binary, batch_size=12, epochs=1000, verbose=0, validation_data=(xtest, ytest_binary))

"""## Visualize the train/test loss and train/test accuracy changing during training"""

hist = history.history

train_loss = hist["loss"]
test_loss = hist["val_loss"]
train_acc = hist["accuracy"]
test_acc = hist["val_accuracy"]

plt.figure()
plt.plot(train_loss, color="blue", label="train loss")
plt.plot(test_loss, color="red", label="test loss")
plt.legend()
plt.xlabel("epochs")
plt.ylabel("loss")
plt.show()
plt.close()

plt.figure()
plt.plot(train_acc, color="blue", label="train accuracy")
plt.plot(test_acc, color="red", label="test accuracy")
plt.legend()
plt.xlabel("epochs")
plt.ylabel("accuracy")
plt.show()
plt.close()

"""## Evaluate the model on the train set"""

ypred_train_binary = model.predict(xtrain)

# make the decision
ypred_train_binary[ypred_train_binary > 0.5] = 1
ypred_train_binary[ypred_train_binary <= 0.5] = 0

accuracy_train_binary = accuracy_score(ytrain_binary, ypred_train_binary)
print("Accuracy of binary classification on the train is: "+str(accuracy_train_binary))

"""## Evaluate the model on the test set"""

ypred_test_binary = model.predict(xtest)

# make the decision
ypred_test_binary[ypred_test_binary > 0.5] = 1
ypred_test_binary[ypred_test_binary <= 0.5] = 0

accuracy_test_binary = accuracy_score(ytest_binary, ypred_test_binary)
print("Accuracy of binary classification on the test is: "+str(accuracy_test_binary))

"""## Exercise: Use the three classes now to do a multi-class classification instead of a Binary Classification, on the same data

## Build the keras model
"""
input_shape = xtrain.shape[1:]
input_layer = tf.keras.layers.Input(input_shape)
output_layer = tf.keras.layers.Dense(units=3, activation="softmax")(input_layer)
model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)
model.summary()

"""## Transform the labels to one hot vectors, for train and test"""

ytrain_one_hot = tf.keras.utils.to_categorical(ytrain, num_classes=3)
ytest_one_hot = tf.keras.utils.to_categorical(ytest, num_classes=3)

"""## Train the model"""

tf.random.set_seed(42)
history = model.fit(xtrain, ytrain_one_hot, batch_size=12, epochs=1000, verbose=0, validation_data=(xtest, ytest_one_hot))

"""## Plot the loss and accuracy changing during training"""

hist = history.history
train_loss = hist["loss"]
test_loss = hist["val_loss"]
train_acc = hist["accuracy"]
test_acc = hist["val_accuracy"]
plt.figure()
plt.plot(train_loss, color="blue", label="train loss")
plt.plot(test_loss, color="red", label="test loss")
plt.legend()
plt.xlabel("epochs")
plt.ylabel("loss")
plt.show()
plt.close()

"""## Evaluate on the train and test sets"""

ypred_train_one_hot = model.predict(xtrain)
ypred_train = np.argmax(ypred_train_one_hot, axis=1)
accuracy_train = accuracy_score(ytrain, ypred_train)
print("Accuracy of multi-class classification on the train is: "+str(accuracy_train))