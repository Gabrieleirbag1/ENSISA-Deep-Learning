# -*- coding: utf-8 -*-
"""2A-IR-DL-Introduction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XUZc0J5o6CE5qkBNt_dAwJtt57JJm2Nd

authors: [Ali Ismail-Fawaz](https://hadifawaz1999.github.io/) and [Germain Forestier](https://germain-forestier.info/)

# Deep Learning: Introduction

## Import used packages
"""

import numpy as np
import os
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

"""## Downloading the dataset"""

#!wget https://hadifawaz1999.github.io/teaching/Ensisa/2A-Info/DeepLearning/datasets/pokemon-stats-data.csv

"""## Reading the data"""

df = pd.read_csv(os.path.join(os.path.dirname(__file__), "pokemon-stats-data.csv"))

df = df.dropna()
df.head()

"""## Extract the features to be used"""

X = df["sp_attack"]
Y = df["sp_defense"]

print("Number of samples in the dataset is "+str(len(X)))

"""## Split the dataset into train and test sets"""

xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=33/100, random_state=42)

print("Number of training examples is "+str(len(xtrain)))
print("Number of testing examples is "+str(len(xtest)))

"""## Plot the 2D attributes"""

plt.figure()
plt.scatter(xtrain, ytrain)
plt.xlabel("Attack (x)")
plt.ylabel("Defense (y)")
plt.show()
plt.close()

"""## Define your linear model as $ypred=w.x$"""

def linear_model(x, w):
  ypred = w * x
  return ypred

"""## Define your error function (cost function) as $average((y-ypred)^2)$"""

def error_function(y, ypred):
  error = np.square(y - ypred).mean()
  return error

"""## Try multiple values of $w$ and calculate the error function with respect to $w$

### Define the the list of possible values of $w$ ranging from $-2.0$ to $8.0$
"""

w_s = np.arange(start=-2.0, stop=8.0, step=0.01)
print(w_s)

"""### Define the empty list of errors for each value in $w_s$"""

list_errors = np.zeros(shape=(w_s.shape), dtype=np.float32)

"""### Go through all values in $w_s$ and calculate the error"""

for i in range(len(w_s)):
  w = w_s[i]
  ypred = linear_model(xtrain, w)
  list_errors[i] = error_function(ytrain, ypred)

"""### Plot the error function with respect to the values of $w_s$"""

plt.figure()
plt.plot(w_s, list_errors)
plt.xlabel(r'$w$')
plt.ylabel("error")
plt.show()
plt.close()

"""### Find the $w$ that minimizes the error"""

index_w_best = list_errors.argmin()
error_train_min = list_errors.min()
w_best = w_s[index_w_best]

print("For w = "+str(w_best)+", the error on all training examples is = "+str(error_train_min))

"""### Evaluate the linear model for $w=w_{best}$ on the test set"""

ypred = linear_model(xtest, w_best)
error_test = error_function(ytest, ypred)
print("For w = "+str(w_best)+", the error on all testing examples is = "+str(error_test))

"""### Visualize the prediction with respect to the true values on the test set"""

min_ypred, min_ytest = np.min(ypred), np.min(ytest)
max_ypred, max_ytest = np.max(ypred), np.max(ytest)

plt.figure()
plt.scatter(ytest, ypred)
plt.xlim(min(min_ypred, min_ytest), max(max_ypred, max_ytest))
plt.ylim(min(min_ypred, min_ytest), max(max_ypred, max_ytest))
plt.xlabel("Ground truth ytest")
plt.ylabel("Predictions ypred")
plt.show()
plt.close()

"""### Plot the straight line $y=w_{best} . x$"""

# Choose min and max borders
x1 = np.min(xtrain)
x2 = np.max(xtrain)

y1 = linear_model(x1, w_best)
y2 = linear_model(x2, w_best)

plt.figure()
plt.scatter(xtrain, ytrain)
plt.plot([x1,x2],[y1,y2], lw=3, color='red')
plt.xlabel("Attack (x)")
plt.ylabel("Defense (y)")
plt.show()
plt.close()

"""# Exercise

## How can we improve the precision (reduce error) on test set ?
"""
def linear_model_with_bias(x, w, b):
  ypred = w * x + b
  return ypred

def train_linear_model_with_bias(xtrain, ytrain, xtest, ytest):
  # Define the the list of possible values of w ranging from -2.0 to 8.0
  w_s = np.arange(start=-2.0, stop=8.0, step=0.1)
  b_s = np.arange(start=-50.0, stop=50.0, step=1.0)

  best_error = float("inf")
  best_w = None
  best_b = None

  # Go through all values in w_s and b_s and calculate the error
  for w in w_s:
    for b in b_s:
      ypred = linear_model_with_bias(xtrain, w, b)
      error = error_function(ytrain, ypred)
      if error < best_error:
        best_error = error
        best_w = w
        best_b = b

  # Evaluate on test set
  ypred_test = linear_model_with_bias(xtest, best_w, best_b)
  test_error = error_function(ytest, ypred_test)

  return best_w, best_b, best_error, test_error

best_w, best_b, train_error, test_error = train_linear_model_with_bias(xtrain, ytrain, xtest, ytest)
print("For w = "+str(best_w)+" and b = "+str(best_b)+", the error on all training examples is = "+str(train_error))
print("For w = "+str(best_w)+" and b = "+str(best_b)+", the error on all testing examples is = "+str(test_error))

plt.figure()
plt.scatter(ytest, linear_model_with_bias(xtest, best_w, best_b))
plt.xlabel("Ground truth ytest")
plt.ylabel("Predictions ypred")
plt.show()